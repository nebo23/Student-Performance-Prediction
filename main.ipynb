import pandas as pd
df = pd.read_csv("student_habits_performance.csv")



df.head()
df.info()
df.shape
df.head(2)
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style="whitegrid")
df.isna().sum().sum()
df = df.dropna()
df
df.duplicated().sum()
import warnings
warnings.filterwarnings("ignore")
df.describe()
df.describe(include="object").columns
categorical_columns = ["gender","part_time_job","diet_quality","parental_education_level", "internet_quality","extracurricular_participation"]
for col in categorical_columns:
    print(f"value Columns for {col}: \n {df[col].value_counts()}")
df.hist(bins=20, edgecolor="black")
plt.tight_layout()
plt.show
for col in categorical_columns:
    sns.countplot(data=df, x = col)
    plt.title(F"Distribution Of {col}")
    plt.xticks(rotation = 45)
    plt.show()
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Connection Matrix")
plt.show()
df.describe().columns
num_features = ['age', 'study_hours_per_day', 'social_media_hours', 'netflix_hours',
       'attendance_percentage', 'sleep_hours', 'exercise_frequency',
       'mental_health_rating']
for feature in num_features:
    sns.scatterplot(data = df, x = feature, y = "exam_score")
    plt.title(f"{feature} vs Exam Score")
    plt.show()
for col in categorical_columns:
    sns.boxplot(data = df, x = col, y="exam_score")
    plt.title(f"Exam Score by {col}")
    plt.xticks(rotation=45)
    plt.show()
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
df.columns
df.head(2)
features = ['study_hours_per_day','attendance_percentage','mental_health_rating','sleep_hours','part_time_job' ]
target = "exam_score"
df_model = df[features + [target]].copy()
df_model
le = LabelEncoder()
df_model["part_time_job"]= le.fit_transform(df_model["part_time_job"])
df_model
x = df_model[features]
y = df_model[target]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)
len(y_test)
len(y_train)
models = {
    "LinearRegression":{
        "model": LinearRegression(),
        "params": {}
    },
    "DecisionTree" :{ 
        "model" :DecisionTreeRegressor(),
        "params" :{"max_depth":[3, 5, 10], "min_samples_split": [2, 5]}
    },
    "RandomForest": {
        "model": RandomForestRegressor(),
        "params":{"n_estimators": [50,100], "max_depth":[5,10]}
    }
}
best_models = []
for name, config in models.items():
    print(f"Training {name}")

    grid = GridSearchCV(config["model"],config["params"], cv=5, scoring="neg_mean_squared_error")
    grid.fit(x_train, y_train)

    y_pred = grid.predict(x_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    best_models.append({
        "model":name,
        "best_params" : grid.best_params_,
        "rmse" : rmse,
        "r2":r2
    })

results_df = pd.DataFrame(best_models)
results_df.sort_values(by="rmse")
import joblib

best_rows = results_df.sort_values(by="rmse").iloc[0]
best_rows
best_models_name = best_rows["model"]
best_models_name
best_model_config = models[best_models_name]
best_model_config
final_model = best_model_config["model"] # (**best_rows["best_params"])
final_model.fit(x,y)
joblib.dump(final_model, "best_model.pkl")
joblib.load("best_model.pkl").predict(x_test)
final_model = best_model_config["model"]
final_model.fit(x, y)
joblib.dump(final_model, "best_model.pkl")
joblib.load("best_model.pkl").predict(x_test)
